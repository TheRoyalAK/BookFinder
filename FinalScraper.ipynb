{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Useful Imports__\n",
    "\n",
    "1. __Pandas:__ This library was used to handle the data.\n",
    "\n",
    "2. __Warnings:__ This was only to ignore the warnings.\n",
    "\n",
    "3. __Requests:__ This was used to send requests to APIs and websites to get the data.\n",
    "\n",
    "4. __BeautifulSoup:__ This library was used to extract data from the source code of websites.\n",
    "\n",
    "5. __Pyisbn:__ This was used later to convert ISBN10 to ISBN13 to search for books on bookswagon.com.\n",
    "\n",
    "6. __Concurrent:__ This was used to do multithreaded scraping.\n",
    "\n",
    "7. __Time:__ This was used to insert a delay if the threads are sending requests too quick and getting denied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from requests import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pyisbn\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Data Ingestion__\n",
    "\n",
    "The following data was collected from the RC of the college with the following fields:-\n",
    "\n",
    "1. __Acc. Date__:- This is the date in which the RC acquired the book.\n",
    "\n",
    "2. __Acc. No.__:- This is the number of book that was assigned to it when acquiring it.\n",
    "\n",
    "3. __Title__:- This is the title of the book.\n",
    "\n",
    "4. __ISBN__:- This is the ISBN of the book. (We will mainly focus on this)\n",
    "\n",
    "5. __Ed./Vol.__:- This signifies if the book was a different edition (than first edition).\n",
    "\n",
    "6. __Place & Publisher__:- This tells us about the place and name of the publisher.\n",
    "\n",
    "7. __Year__:- This is the year of publishing the book.\n",
    "\n",
    "8. __Pages__:- This constitutes of the amount of pages the book has.\n",
    "\n",
    "9. __Class No./Book No.__:- This gives us another identifier for the book.\n",
    "\n",
    "The data was cleaned manually as well as programmatically. It had a lot of inconsistency due to titles of the books containing `,` and `;` both of which are used in `.csv` as delimiters. Some of the ISBNs were wrong and dates were wrong too. ~400 books were removed due to having no ISBN or wrong ISBNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc. Date</th>\n",
       "      <th>Acc. No.</th>\n",
       "      <th>Title</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Author/Editor</th>\n",
       "      <th>Place &amp; Publisher</th>\n",
       "      <th>Year</th>\n",
       "      <th>Page(s)</th>\n",
       "      <th>Class No.Book No.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>1</td>\n",
       "      <td>Network design : management and technical pers...</td>\n",
       "      <td>849334047</td>\n",
       "      <td>Mann-Rubinson, Teresa C.</td>\n",
       "      <td>Boca Raton: CRC Press,</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>405 p.</td>\n",
       "      <td>004.6 MAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>2</td>\n",
       "      <td>Multimedia information analysis and retrieval ...</td>\n",
       "      <td>9783540648260</td>\n",
       "      <td>Ip, Horace H. S.</td>\n",
       "      <td>Berlin: Springer,</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>viii, 264 p.;</td>\n",
       "      <td>004 IPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>3</td>\n",
       "      <td>Multimedia systems : delivering, generating, a...</td>\n",
       "      <td>1852332484</td>\n",
       "      <td>Morris, Tim</td>\n",
       "      <td>London: Springer,</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>xi, 191 p.;</td>\n",
       "      <td>006.7 MOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>4</td>\n",
       "      <td>Principles of Data Mining and Knowledge Discovery</td>\n",
       "      <td>9783540410669</td>\n",
       "      <td>Zytkov, Jan. M.</td>\n",
       "      <td>New York: Springer-Verlag,</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>593 p.</td>\n",
       "      <td>006.3 ZYT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>5</td>\n",
       "      <td>Focusing solutions for data mining : analytica...</td>\n",
       "      <td>3540664297</td>\n",
       "      <td>Reinartz, Thomas</td>\n",
       "      <td>New York: Springer,</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>xiv, 307 p.;</td>\n",
       "      <td>006.3 REI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31527</th>\n",
       "      <td>05-01-2026</td>\n",
       "      <td>36354</td>\n",
       "      <td>The Ruba'iyat of Omar Khayyam</td>\n",
       "      <td>9780140443844</td>\n",
       "      <td>Khayyam, Omar</td>\n",
       "      <td>London : Penguin Books,</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>116 p.</td>\n",
       "      <td>891.5511 KHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31528</th>\n",
       "      <td>05-01-2026</td>\n",
       "      <td>36355</td>\n",
       "      <td>Artificial intelligence for robotics</td>\n",
       "      <td>9781805129592</td>\n",
       "      <td>Francis X.</td>\n",
       "      <td>UK : Packt Publishing,</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>xvii, 325 p. ;</td>\n",
       "      <td>006.3 FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31529</th>\n",
       "      <td>05-01-2026</td>\n",
       "      <td>36356</td>\n",
       "      <td>Too big to fail: The inside story of how wall ...</td>\n",
       "      <td>9780143118244</td>\n",
       "      <td>Sorkin, Andrew Ross</td>\n",
       "      <td>New York : Penguin Books,</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>xx, 618p. ;</td>\n",
       "      <td>330.973 SOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31530</th>\n",
       "      <td>07-01-2026</td>\n",
       "      <td>36357</td>\n",
       "      <td>Digital communications : A foundational approach</td>\n",
       "      <td>9781009429665</td>\n",
       "      <td>Fischer, Robert F. H.</td>\n",
       "      <td>Cambridge : Cambridge University Press,</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>xiv, 397p. ;</td>\n",
       "      <td>621.382 FIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31531</th>\n",
       "      <td>07-01-2026</td>\n",
       "      <td>36358</td>\n",
       "      <td>Grey sister</td>\n",
       "      <td>9781101988909</td>\n",
       "      <td>Lawrence, Mark</td>\n",
       "      <td>Berkley : Penguin,</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>xiv, 397p. ;</td>\n",
       "      <td>813.6 LAW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31532 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Acc. Date  Acc. No.  \\\n",
       "0      08-09-2001         1   \n",
       "1      08-09-2001         2   \n",
       "2      08-09-2001         3   \n",
       "3      08-09-2001         4   \n",
       "4      08-09-2001         5   \n",
       "...           ...       ...   \n",
       "31527  05-01-2026     36354   \n",
       "31528  05-01-2026     36355   \n",
       "31529  05-01-2026     36356   \n",
       "31530  07-01-2026     36357   \n",
       "31531  07-01-2026     36358   \n",
       "\n",
       "                                                   Title           ISBN  \\\n",
       "0      Network design : management and technical pers...      849334047   \n",
       "1      Multimedia information analysis and retrieval ...  9783540648260   \n",
       "2      Multimedia systems : delivering, generating, a...     1852332484   \n",
       "3      Principles of Data Mining and Knowledge Discovery  9783540410669   \n",
       "4      Focusing solutions for data mining : analytica...     3540664297   \n",
       "...                                                  ...            ...   \n",
       "31527                      The Ruba'iyat of Omar Khayyam  9780140443844   \n",
       "31528               Artificial intelligence for robotics  9781805129592   \n",
       "31529  Too big to fail: The inside story of how wall ...  9780143118244   \n",
       "31530   Digital communications : A foundational approach  9781009429665   \n",
       "31531                                        Grey sister  9781101988909   \n",
       "\n",
       "                  Author/Editor                        Place & Publisher  \\\n",
       "0      Mann-Rubinson, Teresa C.                   Boca Raton: CRC Press,   \n",
       "1              Ip, Horace H. S.                        Berlin: Springer,   \n",
       "2                   Morris, Tim                        London: Springer,   \n",
       "3               Zytkov, Jan. M.               New York: Springer-Verlag,   \n",
       "4              Reinartz, Thomas                      New York: Springer,   \n",
       "...                         ...                                      ...   \n",
       "31527             Khayyam, Omar                  London : Penguin Books,   \n",
       "31528                Francis X.                   UK : Packt Publishing,   \n",
       "31529       Sorkin, Andrew Ross                New York : Penguin Books,   \n",
       "31530     Fischer, Robert F. H.  Cambridge : Cambridge University Press,   \n",
       "31531            Lawrence, Mark                       Berkley : Penguin,   \n",
       "\n",
       "         Year         Page(s) Class No.Book No.  \n",
       "0      1999.0          405 p.         004.6 MAN  \n",
       "1      1998.0   viii, 264 p.;           004 IPH  \n",
       "2      2000.0     xi, 191 p.;         006.7 MOR  \n",
       "3      1999.0          593 p.         006.3 ZYT  \n",
       "4      1999.0    xiv, 307 p.;         006.3 REI  \n",
       "...       ...             ...               ...  \n",
       "31527  1981.0         116 p.       891.5511 KHA  \n",
       "31528  2024.0  xvii, 325 p. ;         006.3 FRA  \n",
       "31529  2010.0     xx, 618p. ;       330.973 SOR  \n",
       "31530  2024.0    xiv, 397p. ;       621.382 FIS  \n",
       "31531  2019.0    xiv, 397p. ;         813.6 LAW  \n",
       "\n",
       "[31532 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = './Accession Register-Books _with_ ISBN_numbers.xlsx'\n",
    "data_table = pd.read_excel(data_file)\n",
    "data_table.drop_duplicates(subset='ISBN', keep='first', inplace=True)\n",
    "data_table.sort_values('Acc. No.', inplace=True)\n",
    "data_table.index = range(len(data_table))\n",
    "data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table.to_excel('./Data.xlsx', index_label=\"Index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Data Scraping__\n",
    "\n",
    "This is the header that was used which was taken after visiting a website and going into the developer mode in firefox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'User-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:143.0) Gecko/20100101 Firefox/143.0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first made a scraper that would scrap books from the Google Books site and then if it doesn't find summary there it would fallback to goodreads.com.\n",
    "\n",
    "Later, we realised that google provides an API for books which would be faster than scraping their sites and hence we switched our method. We also realised that alot of the summaries provided by goodreads.com were not of good quality and hence in the second method we stopped using that and searched for better alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING GOOGLE WEBSITE\n",
    "\n",
    "def summary_finder(isbn, header):\n",
    "    try:\n",
    "        summary = \"\"\n",
    "        isbn = str(isbn)\n",
    "        if len(isbn) < 10:\n",
    "            isbn = f\"{'0'*(10 - len(isbn))}{isbn}\"\n",
    "        print(isbn)\n",
    "        search_base_link = f'https://books.google.com/books?vid=ISBN{isbn}'\n",
    "        search_req = request(method='GET', url=search_base_link, headers=header)\n",
    "        book_soup = BeautifulSoup(search_req.text, 'html.parser')\n",
    "        # print('initial google search')\n",
    "        if book_soup.find(name='a', attrs={'class': 'opt-in-header-link'}):\n",
    "            if book_soup.find(name='a', attrs={'class': 'opt-in-header-link'}).text  == \"Try the new Google Books\":\n",
    "                new_link = book_soup.find(name='a', attrs={'class': 'opt-in-header-link'}).attrs['href']\n",
    "                new_req = request(method='GET', url=new_link, headers=header)\n",
    "                new_soup = BeautifulSoup(new_req.text, 'html.parser')\n",
    "                # print('new google search')\n",
    "                book_soup = new_soup\n",
    "        # print('finding summary in google')\n",
    "        summary = book_soup.find(name='div', attrs={'class': 'Mhmsgc'}) or book_soup.find(name='div', attrs={'id': 'synopsistext'})\n",
    "        if not summary:\n",
    "            # print('goodreads')\n",
    "            search_base_link = f'https://www.goodreads.com/search?utf8=%E2%9C%93&search%5Bquery%5D={isbn}'\n",
    "            search_req = request(method='GET', url=search_base_link, headers=header)\n",
    "            book_soup = BeautifulSoup(search_req.text, 'html.parser')\n",
    "            summary = book_soup.find(name='span', attrs={'class': 'Formatted'})\n",
    "    except:\n",
    "        raise ReferenceError(f\"{isbn} failed\")\n",
    "        # return isbn, \"FAILED\"\n",
    "    if summary:\n",
    "        for br in summary.find_all('br'):\n",
    "            br.replace_with('\\\\n')\n",
    "        return isbn, summary.text\n",
    "    return isbn, \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found out that openLibrary has its own API as well and started using it. We noticed that google and openlibrary both give us category/subject which can be really helpful for the semantic search that the data science team would perform and hence came to the conclusion of saving the keywords as well. Also, we found out about the site bookswagon.com which had summary and keywords for a lot more of the books that was not available from google as well as openlibrary.\n",
    "\n",
    "Our function first tries google, then goes for OpenLibrary and then finally bookswagon.com as a fallback. If at any time it finds keywords as well as summary, it directly returns the isbn, keywords and summary as a tuple. And when going from one site to another, it only keeps the higher quality summary/keywords and does not replace it. If the ISBN is given wrong, the code would throw an error at line 60, which tries to convert the ISBN, and so we added a try-except catch to write the ISBNs in a new file that shows the wrong ISBNs.\n",
    "\n",
    "<div style=\"background-color: #e7f3ff; padding: 15px; border-radius: 5px; border-left: 5px solid #007acc; color: #444; width: 95%\">\n",
    "    <b>Note:</b> \n",
    "    <br>\n",
    "    We were not able to scrap much using this function, the details are given later in this file.\n",
    "    <br>\n",
    "    Also note that we did use an API Key from Google but we removed it before pushing it to GitHub.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Google API, OpenLibrary API and bookwagon.com\n",
    "\n",
    "def summary_finder(isbn, header):\n",
    "    try:\n",
    "        summary = \"\"\n",
    "        keywords = []        \n",
    "        isbn = str(isbn)\n",
    "        if len(isbn) < 10:\n",
    "            isbn = f\"{'0'*(10 - len(isbn))}{isbn}\"\n",
    "        # print(isbn)\n",
    "        \n",
    "        # print('openlibrary')\n",
    "        api_link = f\"https://www.openlibrary.org/isbn/{isbn}\"\n",
    "        api_req = request(method=\"GET\", url=api_link, headers=header)\n",
    "        try:\n",
    "            api_res = api_req.json()\n",
    "            if 'subjects' in api_res:\n",
    "                keywords = api_res['subjects']\n",
    "            if 'description' in api_res:\n",
    "                if type(api_res['description']) == dict:\n",
    "                    summary = api_res['description']['value']\n",
    "                else:\n",
    "                    summary = api_res['description']\n",
    "            if not summary and 'first_sentence' in api_res:\n",
    "                if type(api_res['first_sentence']) == dict:\n",
    "                    summary = api_res['first_sentence']['value']\n",
    "                else:\n",
    "                    summary = api_res['first_sentence']\n",
    "            if 'works' in api_res:\n",
    "                api_link = f\"https://www.openlibrary.org{api_res['works'][0]['key']}.json\"\n",
    "                api_req = request(method=\"GET\", url = api_link, headers=header)\n",
    "                api_res = api_req.json()\n",
    "                if 'subjects' in api_res:\n",
    "                    if len(keywords) < len(api_res['subjects']):\n",
    "                        keywords = api_res['subjects']\n",
    "                if 'description' in api_res:\n",
    "                    if type(api_res['description']) == dict and len(api_res['description']['value']) > len(summary):\n",
    "                        summary = api_res['description']['value']\n",
    "                    else:\n",
    "                        if len(api_res['description']) > len(summary):\n",
    "                            summary = api_res['description']\n",
    "            if summary and keywords:\n",
    "                return isbn, ', '.join(keywords), summary\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "            \n",
    "        \n",
    "        # print('bookswagon')\n",
    "        if len(isbn) == 10:\n",
    "            try:\n",
    "                isbn = pyisbn.convert(isbn)\n",
    "            except:\n",
    "                return isbn, \"\", \"\"\n",
    "        search_base_link = f'https://www.bookswagon.com/book/c/{isbn}'\n",
    "        search_req = request(method='GET', url=search_base_link, headers=header)\n",
    "        book_soup = BeautifulSoup(search_req.text, 'html.parser')\n",
    "        new_summary = book_soup.find(name='div', attrs={'id': 'aboutbook'})\n",
    "        if new_summary:\n",
    "            new_summary = new_summary.p\n",
    "            if len(summary) < len(new_summary.text.strip()):\n",
    "                summary = new_summary.text.strip()\n",
    "        cats = book_soup.find('ul', attrs={'class': 'blacklistreview'})\n",
    "        if cats:\n",
    "            cats = cats.find_all('a')\n",
    "            cats = list({k.text.strip() for k in cats})\n",
    "            if len(cats) > len(keywords):\n",
    "                keywords = cats\n",
    "        if keywords and summary:\n",
    "            return isbn, ', '.join(keywords), summary\n",
    "                \n",
    "                \n",
    "        # print('finding summary in google')\n",
    "        api_link = f\"https://www.googleapis.com/books/v1/volumes?q=isbn:{isbn}\"\n",
    "        api_req = request(method='GET', url=api_link, headers=header)\n",
    "        api_res = api_req.json()\n",
    "        if api_res['totalItems'] != 0:\n",
    "            if 'description' in api_res['items'][0]['volumeInfo'] and len(summary) < len(api_res['items'][0]['volumeInfo']['description']):\n",
    "                summary = api_res['items'][0]['volumeInfo']['description']\n",
    "            if 'categories' in api_res['items'][0]['volumeInfo'] and len(keywords) < len(api_res['items'][0]['volumeInfo']['categories']):\n",
    "                keywords = api_res['items'][0]['volumeInfo']['categories']\n",
    "        \n",
    "        return isbn, ', '.join(keywords), summary\n",
    "        \n",
    "    except:\n",
    "        with open('./notFound.txt', 'a') as nf:\n",
    "            nf.write(f'{isbn}\\n')\n",
    "        return isbn, \"\", \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used multithreading to work at several books in a batch at once. There were several oversights that were looked into when applying the function using something similar to the following function which instead of retrying, raised the Error with the details of the book and error. The oversigts and bugs were then fixed. Later this function, was only getting error when one of the providers were giving us timeout. So, we made this recursive after waiting for 5 seconds for the timeout to go away and continue from where it left off. Also this concatinates the new results with the old ones that we found in previous iterations.\n",
    "\n",
    "<div style=\"background-color: #e7f3ff; padding: 15px; border-radius: 5px; border-left: 5px solid #007acc; color: #444; width: 95%\">\n",
    "    <b>Note:</b> \n",
    "    <br>\n",
    "    We were supervising this function till 1600 books. All that time the function was working perfectly while giving the keywords and summary. After 8000+ books were scraped, the function ran into an error loop (due to the try except clause). When we dug deeper into what happened, we found the last bug which was openLibrary sending us summary as <code>dict</code> sometimes and not <code>str</code>. We fixed that instantly, but after that when we checked the output file, we found out that the summary of most of the books (~97%) were overwritten for some reason. After which we didn't have enough time to scrap that data again and submit this project before deadline and hence we asked another team for their scraped data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_and_save(start_idx):\n",
    "    for i in range(start_idx, 3500):\n",
    "        books = []\n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            futures = [\n",
    "                executor.submit(summary_finder, isbn, header)\n",
    "                for isbn in data_table['ISBN'][10*i:10*(i+1)]\n",
    "            ]\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                isbn, keywords, summary = future.result()\n",
    "                books.append({\n",
    "                    'isbn': isbn,\n",
    "                    'keywords': keywords,\n",
    "                    'summary': summary\n",
    "                })\n",
    "            \n",
    "        pd.DataFrame(books).to_excel(f'./Summaries/{i}.xlsx', index=False)\n",
    "        \n",
    "# scrap_and_save(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this function, we have created a seperate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Data Merging__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = pd.read_excel('./Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_isbn(isbn):\n",
    "    isbn = str(isbn)\n",
    "    if len(isbn) < 10:\n",
    "        isbn = f\"{'0' * (10-len(isbn))}{isbn}\"\n",
    "    if len(isbn) == 10:\n",
    "        try:\n",
    "            new_isbn = pyisbn.convert(isbn)\n",
    "        except:\n",
    "            return isbn\n",
    "    else:\n",
    "        new_isbn = isbn\n",
    "    return new_isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Acc. Date</th>\n",
       "      <th>Acc. No.</th>\n",
       "      <th>Title</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Author/Editor</th>\n",
       "      <th>Place &amp; Publisher</th>\n",
       "      <th>Year</th>\n",
       "      <th>Page(s)</th>\n",
       "      <th>Class No.Book No.</th>\n",
       "      <th>Chunk</th>\n",
       "      <th>Norm ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>1</td>\n",
       "      <td>Network design : management and technical pers...</td>\n",
       "      <td>849334047</td>\n",
       "      <td>Mann-Rubinson, Teresa C.</td>\n",
       "      <td>Boca Raton: CRC Press,</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>405 p.</td>\n",
       "      <td>004.6 MAN</td>\n",
       "      <td>0</td>\n",
       "      <td>9780849334047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>2</td>\n",
       "      <td>Multimedia information analysis and retrieval ...</td>\n",
       "      <td>9783540648260</td>\n",
       "      <td>Ip, Horace H. S.</td>\n",
       "      <td>Berlin: Springer,</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>viii, 264 p.;</td>\n",
       "      <td>004 IPH</td>\n",
       "      <td>0</td>\n",
       "      <td>9783540648260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>3</td>\n",
       "      <td>Multimedia systems : delivering, generating, a...</td>\n",
       "      <td>1852332484</td>\n",
       "      <td>Morris, Tim</td>\n",
       "      <td>London: Springer,</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>xi, 191 p.;</td>\n",
       "      <td>006.7 MOR</td>\n",
       "      <td>0</td>\n",
       "      <td>9781852332488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>4</td>\n",
       "      <td>Principles of Data Mining and Knowledge Discovery</td>\n",
       "      <td>9783540410669</td>\n",
       "      <td>Zytkov, Jan. M.</td>\n",
       "      <td>New York: Springer-Verlag,</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>593 p.</td>\n",
       "      <td>006.3 ZYT</td>\n",
       "      <td>0</td>\n",
       "      <td>9783540410669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>5</td>\n",
       "      <td>Focusing solutions for data mining : analytica...</td>\n",
       "      <td>3540664297</td>\n",
       "      <td>Reinartz, Thomas</td>\n",
       "      <td>New York: Springer,</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>xiv, 307 p.;</td>\n",
       "      <td>006.3 REI</td>\n",
       "      <td>0</td>\n",
       "      <td>9783540664291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31527</th>\n",
       "      <td>31527</td>\n",
       "      <td>05-01-2026</td>\n",
       "      <td>36354</td>\n",
       "      <td>The Ruba'iyat of Omar Khayyam</td>\n",
       "      <td>9780140443844</td>\n",
       "      <td>Khayyam, Omar</td>\n",
       "      <td>London : Penguin Books,</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>116 p.</td>\n",
       "      <td>891.5511 KHA</td>\n",
       "      <td>3152</td>\n",
       "      <td>9780140443844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31528</th>\n",
       "      <td>31528</td>\n",
       "      <td>05-01-2026</td>\n",
       "      <td>36355</td>\n",
       "      <td>Artificial intelligence for robotics</td>\n",
       "      <td>9781805129592</td>\n",
       "      <td>Francis X.</td>\n",
       "      <td>UK : Packt Publishing,</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>xvii, 325 p. ;</td>\n",
       "      <td>006.3 FRA</td>\n",
       "      <td>3152</td>\n",
       "      <td>9781805129592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31529</th>\n",
       "      <td>31529</td>\n",
       "      <td>05-01-2026</td>\n",
       "      <td>36356</td>\n",
       "      <td>Too big to fail: The inside story of how wall ...</td>\n",
       "      <td>9780143118244</td>\n",
       "      <td>Sorkin, Andrew Ross</td>\n",
       "      <td>New York : Penguin Books,</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>xx, 618p. ;</td>\n",
       "      <td>330.973 SOR</td>\n",
       "      <td>3152</td>\n",
       "      <td>9780143118244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31530</th>\n",
       "      <td>31530</td>\n",
       "      <td>07-01-2026</td>\n",
       "      <td>36357</td>\n",
       "      <td>Digital communications : A foundational approach</td>\n",
       "      <td>9781009429665</td>\n",
       "      <td>Fischer, Robert F. H.</td>\n",
       "      <td>Cambridge : Cambridge University Press,</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>xiv, 397p. ;</td>\n",
       "      <td>621.382 FIS</td>\n",
       "      <td>3153</td>\n",
       "      <td>9781009429665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31531</th>\n",
       "      <td>31531</td>\n",
       "      <td>07-01-2026</td>\n",
       "      <td>36358</td>\n",
       "      <td>Grey sister</td>\n",
       "      <td>9781101988909</td>\n",
       "      <td>Lawrence, Mark</td>\n",
       "      <td>Berkley : Penguin,</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>xiv, 397p. ;</td>\n",
       "      <td>813.6 LAW</td>\n",
       "      <td>3153</td>\n",
       "      <td>9781101988909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31532 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index   Acc. Date  Acc. No.  \\\n",
       "0          0  08-09-2001         1   \n",
       "1          1  08-09-2001         2   \n",
       "2          2  08-09-2001         3   \n",
       "3          3  08-09-2001         4   \n",
       "4          4  08-09-2001         5   \n",
       "...      ...         ...       ...   \n",
       "31527  31527  05-01-2026     36354   \n",
       "31528  31528  05-01-2026     36355   \n",
       "31529  31529  05-01-2026     36356   \n",
       "31530  31530  07-01-2026     36357   \n",
       "31531  31531  07-01-2026     36358   \n",
       "\n",
       "                                                   Title           ISBN  \\\n",
       "0      Network design : management and technical pers...      849334047   \n",
       "1      Multimedia information analysis and retrieval ...  9783540648260   \n",
       "2      Multimedia systems : delivering, generating, a...     1852332484   \n",
       "3      Principles of Data Mining and Knowledge Discovery  9783540410669   \n",
       "4      Focusing solutions for data mining : analytica...     3540664297   \n",
       "...                                                  ...            ...   \n",
       "31527                      The Ruba'iyat of Omar Khayyam  9780140443844   \n",
       "31528               Artificial intelligence for robotics  9781805129592   \n",
       "31529  Too big to fail: The inside story of how wall ...  9780143118244   \n",
       "31530   Digital communications : A foundational approach  9781009429665   \n",
       "31531                                        Grey sister  9781101988909   \n",
       "\n",
       "                  Author/Editor                        Place & Publisher  \\\n",
       "0      Mann-Rubinson, Teresa C.                   Boca Raton: CRC Press,   \n",
       "1              Ip, Horace H. S.                        Berlin: Springer,   \n",
       "2                   Morris, Tim                        London: Springer,   \n",
       "3               Zytkov, Jan. M.               New York: Springer-Verlag,   \n",
       "4              Reinartz, Thomas                      New York: Springer,   \n",
       "...                         ...                                      ...   \n",
       "31527             Khayyam, Omar                  London : Penguin Books,   \n",
       "31528                Francis X.                   UK : Packt Publishing,   \n",
       "31529       Sorkin, Andrew Ross                New York : Penguin Books,   \n",
       "31530     Fischer, Robert F. H.  Cambridge : Cambridge University Press,   \n",
       "31531            Lawrence, Mark                       Berkley : Penguin,   \n",
       "\n",
       "         Year         Page(s) Class No.Book No.  Chunk      Norm ISBN  \n",
       "0      1999.0          405 p.         004.6 MAN      0  9780849334047  \n",
       "1      1998.0   viii, 264 p.;           004 IPH      0  9783540648260  \n",
       "2      2000.0     xi, 191 p.;         006.7 MOR      0  9781852332488  \n",
       "3      1999.0          593 p.         006.3 ZYT      0  9783540410669  \n",
       "4      1999.0    xiv, 307 p.;         006.3 REI      0  9783540664291  \n",
       "...       ...             ...               ...    ...            ...  \n",
       "31527  1981.0         116 p.       891.5511 KHA   3152  9780140443844  \n",
       "31528  2024.0  xvii, 325 p. ;         006.3 FRA   3152  9781805129592  \n",
       "31529  2010.0     xx, 618p. ;       330.973 SOR   3152  9780143118244  \n",
       "31530  2024.0    xiv, 397p. ;       621.382 FIS   3153  9781009429665  \n",
       "31531  2019.0    xiv, 397p. ;         813.6 LAW   3153  9781101988909  \n",
       "\n",
       "[31532 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_table['Chunk'] = data_table['Index'] //10\n",
    "data_table['Norm ISBN'] = data_table['ISBN'].apply(norm_isbn)\n",
    "data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_table = pd.DataFrame(columns=['isbn', 'keywords', 'summary', 'Chunk', 'Norm ISBN'])\n",
    "location = './Summaries/'\n",
    "for chunk in range(0, 3154):\n",
    "    book_chunk = pd.read_excel(f\"{location}{chunk}.xlsx\")\n",
    "    book_chunk['Norm ISBN'] = book_chunk['isbn'].apply(norm_isbn)\n",
    "    book_chunk['Chunk'] = chunk\n",
    "    book_table = pd.concat([book_table, book_chunk], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>isbn</th>\n",
       "      <th>keywords</th>\n",
       "      <th>summary</th>\n",
       "      <th>Chunk</th>\n",
       "      <th>Norm ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9783540410669</td>\n",
       "      <td>The Arts, Interdisciplinary studies, Internet ...</td>\n",
       "      <td>This book constitutes the refereed proceedings...</td>\n",
       "      <td>0</td>\n",
       "      <td>9783540410669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9783540648260</td>\n",
       "      <td>Digital signal processing (DSP), Computing and...</td>\n",
       "      <td>This book constitutes the refereed proceedings...</td>\n",
       "      <td>0</td>\n",
       "      <td>9783540648260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9781852332488</td>\n",
       "      <td>Computing and Information Technology, Computer...</td>\n",
       "      <td>What are Multimedia Systems? This book is inte...</td>\n",
       "      <td>0</td>\n",
       "      <td>9781852332488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9780849334047</td>\n",
       "      <td>Computing and Information Technology, Computer...</td>\n",
       "      <td>Network Design outlines the fundamental princi...</td>\n",
       "      <td>0</td>\n",
       "      <td>9780849334047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9783540660828</td>\n",
       "      <td>The Arts, Internet guides and online services,...</td>\n",
       "      <td>This book constitutes the refereed proceedings...</td>\n",
       "      <td>0</td>\n",
       "      <td>9783540660828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31527</th>\n",
       "      <td>31527</td>\n",
       "      <td>9781805129592</td>\n",
       "      <td>Storage media and peripherals, Computer hardwa...</td>\n",
       "      <td>Let an AI and robotics expert help you apply A...</td>\n",
       "      <td>3152</td>\n",
       "      <td>9781805129592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31528</th>\n",
       "      <td>31528</td>\n",
       "      <td>9780143118244</td>\n",
       "      <td>Economic geography, Geography, Economic histor...</td>\n",
       "      <td>NEW YORK TIMES BESTELLER • The definitive acco...</td>\n",
       "      <td>3152</td>\n",
       "      <td>9780143118244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31529</th>\n",
       "      <td>31529</td>\n",
       "      <td>9780140443844</td>\n",
       "      <td>Poetry by individual poets, Poetry, Biography,...</td>\n",
       "      <td>Only widely-available edition of Khayyam's lyr...</td>\n",
       "      <td>3152</td>\n",
       "      <td>9780140443844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31530</th>\n",
       "      <td>31530</td>\n",
       "      <td>9781009429665</td>\n",
       "      <td>Communications engineering / telecommunication...</td>\n",
       "      <td>Introducing the fundamentals of digital commun...</td>\n",
       "      <td>3153</td>\n",
       "      <td>9781009429665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31531</th>\n",
       "      <td>31531</td>\n",
       "      <td>9781101988909</td>\n",
       "      <td>Fantasy, Fiction and Related items, Adventure ...</td>\n",
       "      <td>The second novel in a brilliant fantasy trilog...</td>\n",
       "      <td>3153</td>\n",
       "      <td>9781101988909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31532 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index           isbn  \\\n",
       "0          0  9783540410669   \n",
       "1          1  9783540648260   \n",
       "2          2  9781852332488   \n",
       "3          3  9780849334047   \n",
       "4          4  9783540660828   \n",
       "...      ...            ...   \n",
       "31527  31527  9781805129592   \n",
       "31528  31528  9780143118244   \n",
       "31529  31529  9780140443844   \n",
       "31530  31530  9781009429665   \n",
       "31531  31531  9781101988909   \n",
       "\n",
       "                                                keywords  \\\n",
       "0      The Arts, Interdisciplinary studies, Internet ...   \n",
       "1      Digital signal processing (DSP), Computing and...   \n",
       "2      Computing and Information Technology, Computer...   \n",
       "3      Computing and Information Technology, Computer...   \n",
       "4      The Arts, Internet guides and online services,...   \n",
       "...                                                  ...   \n",
       "31527  Storage media and peripherals, Computer hardwa...   \n",
       "31528  Economic geography, Geography, Economic histor...   \n",
       "31529  Poetry by individual poets, Poetry, Biography,...   \n",
       "31530  Communications engineering / telecommunication...   \n",
       "31531  Fantasy, Fiction and Related items, Adventure ...   \n",
       "\n",
       "                                                 summary Chunk      Norm ISBN  \n",
       "0      This book constitutes the refereed proceedings...     0  9783540410669  \n",
       "1      This book constitutes the refereed proceedings...     0  9783540648260  \n",
       "2      What are Multimedia Systems? This book is inte...     0  9781852332488  \n",
       "3      Network Design outlines the fundamental princi...     0  9780849334047  \n",
       "4      This book constitutes the refereed proceedings...     0  9783540660828  \n",
       "...                                                  ...   ...            ...  \n",
       "31527  Let an AI and robotics expert help you apply A...  3152  9781805129592  \n",
       "31528  NEW YORK TIMES BESTELLER • The definitive acco...  3152  9780143118244  \n",
       "31529  Only widely-available edition of Khayyam's lyr...  3152  9780140443844  \n",
       "31530  Introducing the fundamentals of digital commun...  3153  9781009429665  \n",
       "31531  The second novel in a brilliant fantasy trilog...  3153  9781101988909  \n",
       "\n",
       "[31532 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_reset = book_table.reset_index()\n",
    "book_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table_merge = data_table.merge(book_reset, on=['Chunk', 'Norm ISBN'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = data_table_merge.drop_duplicates(['Index'])[[\n",
    "    'Acc. Date', \n",
    "    'Acc. No.', \n",
    "    'Title', \n",
    "    'ISBN', \n",
    "    'Norm ISBN', \n",
    "    'Author/Editor', \n",
    "    'Place & Publisher', \n",
    "    'Year', \n",
    "    'Page(s)', \n",
    "    'Class No.Book No.', \n",
    "    'keywords', \n",
    "    'summary'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.columns = [\n",
    "    'AccDate',\n",
    "    'AccNo',\n",
    "    'Title',\n",
    "    'ISBN',\n",
    "    'ISBN13',\n",
    "    'Author',\n",
    "    'Publisher',\n",
    "    'Year',\n",
    "    'Pages',\n",
    "    'DDC',\n",
    "    'Keywords',\n",
    "    'Summary'  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccDate</th>\n",
       "      <th>AccNo</th>\n",
       "      <th>Title</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISBN13</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Year</th>\n",
       "      <th>Pages</th>\n",
       "      <th>DDC</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>1</td>\n",
       "      <td>Network design : management and technical pers...</td>\n",
       "      <td>849334047</td>\n",
       "      <td>9780849334047</td>\n",
       "      <td>Mann-Rubinson, Teresa C.</td>\n",
       "      <td>Boca Raton: CRC Press,</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>405 p.</td>\n",
       "      <td>004.6 MAN</td>\n",
       "      <td>Computing and Information Technology, Computer...</td>\n",
       "      <td>Network Design outlines the fundamental princi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>2</td>\n",
       "      <td>Multimedia information analysis and retrieval ...</td>\n",
       "      <td>9783540648260</td>\n",
       "      <td>9783540648260</td>\n",
       "      <td>Ip, Horace H. S.</td>\n",
       "      <td>Berlin: Springer,</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>viii, 264 p.;</td>\n",
       "      <td>004 IPH</td>\n",
       "      <td>Digital signal processing (DSP), Computing and...</td>\n",
       "      <td>This book constitutes the refereed proceedings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>3</td>\n",
       "      <td>Multimedia systems : delivering, generating, a...</td>\n",
       "      <td>1852332484</td>\n",
       "      <td>9781852332488</td>\n",
       "      <td>Morris, Tim</td>\n",
       "      <td>London: Springer,</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>xi, 191 p.;</td>\n",
       "      <td>006.7 MOR</td>\n",
       "      <td>Computing and Information Technology, Computer...</td>\n",
       "      <td>What are Multimedia Systems? This book is inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>4</td>\n",
       "      <td>Principles of Data Mining and Knowledge Discovery</td>\n",
       "      <td>9783540410669</td>\n",
       "      <td>9783540410669</td>\n",
       "      <td>Zytkov, Jan. M.</td>\n",
       "      <td>New York: Springer-Verlag,</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>593 p.</td>\n",
       "      <td>006.3 ZYT</td>\n",
       "      <td>The Arts, Interdisciplinary studies, Internet ...</td>\n",
       "      <td>This book constitutes the refereed proceedings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-09-2001</td>\n",
       "      <td>5</td>\n",
       "      <td>Focusing solutions for data mining : analytica...</td>\n",
       "      <td>3540664297</td>\n",
       "      <td>9783540664291</td>\n",
       "      <td>Reinartz, Thomas</td>\n",
       "      <td>New York: Springer,</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>xiv, 307 p.;</td>\n",
       "      <td>006.3 REI</td>\n",
       "      <td>Data capture and analysis, Research and inform...</td>\n",
       "      <td>In the first part, this book analyzes the know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31551</th>\n",
       "      <td>05-01-2026</td>\n",
       "      <td>36354</td>\n",
       "      <td>The Ruba'iyat of Omar Khayyam</td>\n",
       "      <td>9780140443844</td>\n",
       "      <td>9780140443844</td>\n",
       "      <td>Khayyam, Omar</td>\n",
       "      <td>London : Penguin Books,</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>116 p.</td>\n",
       "      <td>891.5511 KHA</td>\n",
       "      <td>Poetry by individual poets, Poetry, Biography,...</td>\n",
       "      <td>Only widely-available edition of Khayyam's lyr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31552</th>\n",
       "      <td>05-01-2026</td>\n",
       "      <td>36355</td>\n",
       "      <td>Artificial intelligence for robotics</td>\n",
       "      <td>9781805129592</td>\n",
       "      <td>9781805129592</td>\n",
       "      <td>Francis X.</td>\n",
       "      <td>UK : Packt Publishing,</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>xvii, 325 p. ;</td>\n",
       "      <td>006.3 FRA</td>\n",
       "      <td>Storage media and peripherals, Computer hardwa...</td>\n",
       "      <td>Let an AI and robotics expert help you apply A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31553</th>\n",
       "      <td>05-01-2026</td>\n",
       "      <td>36356</td>\n",
       "      <td>Too big to fail: The inside story of how wall ...</td>\n",
       "      <td>9780143118244</td>\n",
       "      <td>9780143118244</td>\n",
       "      <td>Sorkin, Andrew Ross</td>\n",
       "      <td>New York : Penguin Books,</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>xx, 618p. ;</td>\n",
       "      <td>330.973 SOR</td>\n",
       "      <td>Economic geography, Geography, Economic histor...</td>\n",
       "      <td>NEW YORK TIMES BESTELLER • The definitive acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31554</th>\n",
       "      <td>07-01-2026</td>\n",
       "      <td>36357</td>\n",
       "      <td>Digital communications : A foundational approach</td>\n",
       "      <td>9781009429665</td>\n",
       "      <td>9781009429665</td>\n",
       "      <td>Fischer, Robert F. H.</td>\n",
       "      <td>Cambridge : Cambridge University Press,</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>xiv, 397p. ;</td>\n",
       "      <td>621.382 FIS</td>\n",
       "      <td>Communications engineering / telecommunication...</td>\n",
       "      <td>Introducing the fundamentals of digital commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31555</th>\n",
       "      <td>07-01-2026</td>\n",
       "      <td>36358</td>\n",
       "      <td>Grey sister</td>\n",
       "      <td>9781101988909</td>\n",
       "      <td>9781101988909</td>\n",
       "      <td>Lawrence, Mark</td>\n",
       "      <td>Berkley : Penguin,</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>xiv, 397p. ;</td>\n",
       "      <td>813.6 LAW</td>\n",
       "      <td>Fantasy, Fiction and Related items, Adventure ...</td>\n",
       "      <td>The second novel in a brilliant fantasy trilog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31532 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AccDate  AccNo                                              Title  \\\n",
       "0      08-09-2001      1  Network design : management and technical pers...   \n",
       "1      08-09-2001      2  Multimedia information analysis and retrieval ...   \n",
       "2      08-09-2001      3  Multimedia systems : delivering, generating, a...   \n",
       "3      08-09-2001      4  Principles of Data Mining and Knowledge Discovery   \n",
       "4      08-09-2001      5  Focusing solutions for data mining : analytica...   \n",
       "...           ...    ...                                                ...   \n",
       "31551  05-01-2026  36354                      The Ruba'iyat of Omar Khayyam   \n",
       "31552  05-01-2026  36355               Artificial intelligence for robotics   \n",
       "31553  05-01-2026  36356  Too big to fail: The inside story of how wall ...   \n",
       "31554  07-01-2026  36357   Digital communications : A foundational approach   \n",
       "31555  07-01-2026  36358                                        Grey sister   \n",
       "\n",
       "                ISBN         ISBN13                    Author  \\\n",
       "0          849334047  9780849334047  Mann-Rubinson, Teresa C.   \n",
       "1      9783540648260  9783540648260          Ip, Horace H. S.   \n",
       "2         1852332484  9781852332488               Morris, Tim   \n",
       "3      9783540410669  9783540410669           Zytkov, Jan. M.   \n",
       "4         3540664297  9783540664291          Reinartz, Thomas   \n",
       "...              ...            ...                       ...   \n",
       "31551  9780140443844  9780140443844             Khayyam, Omar   \n",
       "31552  9781805129592  9781805129592                Francis X.   \n",
       "31553  9780143118244  9780143118244       Sorkin, Andrew Ross   \n",
       "31554  9781009429665  9781009429665     Fischer, Robert F. H.   \n",
       "31555  9781101988909  9781101988909            Lawrence, Mark   \n",
       "\n",
       "                                     Publisher    Year           Pages  \\\n",
       "0                       Boca Raton: CRC Press,  1999.0          405 p.   \n",
       "1                            Berlin: Springer,  1998.0   viii, 264 p.;   \n",
       "2                            London: Springer,  2000.0     xi, 191 p.;   \n",
       "3                   New York: Springer-Verlag,  1999.0          593 p.   \n",
       "4                          New York: Springer,  1999.0    xiv, 307 p.;   \n",
       "...                                        ...     ...             ...   \n",
       "31551                  London : Penguin Books,  1981.0         116 p.    \n",
       "31552                   UK : Packt Publishing,  2024.0  xvii, 325 p. ;   \n",
       "31553                New York : Penguin Books,  2010.0     xx, 618p. ;   \n",
       "31554  Cambridge : Cambridge University Press,  2024.0    xiv, 397p. ;   \n",
       "31555                       Berkley : Penguin,  2019.0    xiv, 397p. ;   \n",
       "\n",
       "                DDC                                           Keywords  \\\n",
       "0         004.6 MAN  Computing and Information Technology, Computer...   \n",
       "1           004 IPH  Digital signal processing (DSP), Computing and...   \n",
       "2         006.7 MOR  Computing and Information Technology, Computer...   \n",
       "3         006.3 ZYT  The Arts, Interdisciplinary studies, Internet ...   \n",
       "4         006.3 REI  Data capture and analysis, Research and inform...   \n",
       "...             ...                                                ...   \n",
       "31551  891.5511 KHA  Poetry by individual poets, Poetry, Biography,...   \n",
       "31552     006.3 FRA  Storage media and peripherals, Computer hardwa...   \n",
       "31553   330.973 SOR  Economic geography, Geography, Economic histor...   \n",
       "31554   621.382 FIS  Communications engineering / telecommunication...   \n",
       "31555     813.6 LAW  Fantasy, Fiction and Related items, Adventure ...   \n",
       "\n",
       "                                                 Summary  \n",
       "0      Network Design outlines the fundamental princi...  \n",
       "1      This book constitutes the refereed proceedings...  \n",
       "2      What are Multimedia Systems? This book is inte...  \n",
       "3      This book constitutes the refereed proceedings...  \n",
       "4      In the first part, this book analyzes the know...  \n",
       "...                                                  ...  \n",
       "31551  Only widely-available edition of Khayyam's lyr...  \n",
       "31552  Let an AI and robotics expert help you apply A...  \n",
       "31553  NEW YORK TIMES BESTELLER • The definitive acco...  \n",
       "31554  Introducing the fundamentals of digital commun...  \n",
       "31555  The second novel in a brilliant fantasy trilog...  \n",
       "\n",
       "[31532 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_excel('./Final_Data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Stats for books__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No summaries:                                   4006 ( 12.70 % )\n",
      "No keywords:                                    4268 ( 13.54 % )\n",
      "Neither summary nor keywords:                   3391 ( 10.75 % )\n",
      "Total Books:                                   31532\n"
     ]
    }
   ],
   "source": [
    "total = len(final_data)\n",
    "\n",
    "# Books with no summaries\n",
    "no_sum = final_data['Summary'].isna().sum()\n",
    "print(f\"No summaries: {f'{no_sum} ( {no_sum/total*100:.2f} % )':>50}\")\n",
    "\n",
    "# Books with no keywords\n",
    "no_key = final_data['Keywords'].isna().sum()\n",
    "print(f\"No keywords: {f'{no_key} ( {no_key/total*100:.2f} % )':>51}\")\n",
    "\n",
    "# Books with no extra details\n",
    "no_sumkey = final_data[final_data['Summary'].isna() & final_data['Keywords'].isna()].shape[0]\n",
    "print(f\"Neither summary nor keywords: {f'{no_sumkey} ( {no_sumkey/total*100:.2f} % )':>34}\")\n",
    "\n",
    "# Total\n",
    "print(f\"Total Books: {total:>39}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra\n",
    "\n",
    "When trying to clean the data given by the RC, we found out that the RC has even more data that is not only helpful but also crucial in their website. They already had a lot of summary, subjects, description, contributor names which were not in the data provided. And hence we did try to scrap from there, but later stopped doing so after the warning from the faculty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Correction from RC website scraping\n",
    "\n",
    "\n",
    "for i in range(334, 2000):\n",
    "    not_Found = []\n",
    "    cleaned_data_table = pd.DataFrame(columns=[\n",
    "                        'Acc. No.', \n",
    "                        'Acc. Date', \n",
    "                        'ISBN', \n",
    "                        'Title', \n",
    "                        'Edition', \n",
    "                        'Author', \n",
    "                        'Contributor(s)',\n",
    "                        'Series',\n",
    "                        'Publisher', \n",
    "                        'Publication Date', \n",
    "                        'Publisher Location', \n",
    "                        'Description', \n",
    "                        'Subjects', \n",
    "                        'DDC', \n",
    "                        'Summary'\n",
    "                    ])\n",
    "    try:\n",
    "        for acc_no, acc_date, isbn in data_table[10*i:10*(i+1)].itertuples(index=False):\n",
    "            while len(isbn) < 10:\n",
    "                isbn = f'0{isbn}'\n",
    "            # print(isbn)\n",
    "            search_base_link = f'https://opac.daiict.ac.in/cgi-bin/koha/opac-search.pl?q={isbn}'\n",
    "            print('searched', isbn)\n",
    "            search_req = request('GET', search_base_link, headers=header)\n",
    "            rc_soup = BeautifulSoup(search_req.text, 'html.parser')\n",
    "            if rc_soup.find('div', {'id': 'didyoumean'}):\n",
    "                if rc_soup.find('h1', {'id': 'numresults'}).text == 'No results found!':\n",
    "                    not_Found.append((acc_no, acc_date, isbn))\n",
    "                    print(isbn, 'not found')\n",
    "                    print(f'{\"-\"*30}')\n",
    "                    continue\n",
    "                print('clicking results')\n",
    "                results = rc_soup.find_all('a', {'class': 'title'})\n",
    "                for idx, result in enumerate(results):\n",
    "                    search_base_link = f\"https://opac.daiict.ac.in{result.get_attribute_list('href')[0]}\"\n",
    "                    search_req = request('GET', search_base_link, headers=header)\n",
    "                    rc_soup = BeautifulSoup(search_req.text, 'html.parser')\n",
    "                    if isbn == rc_soup.find('span', {'property': 'isbn'}).text.strip():\n",
    "                        break\n",
    "                    print(f'going to next result {idx}/{len(results)}')\n",
    "            title = rc_soup.find('h1', {'class': 'title'}).text\n",
    "            # print(repr(title))\n",
    "            # if rc_soup.find('span', {'property': 'bookEdition'}):\n",
    "            edition = rc_soup.find('span', {'property': 'bookEdition'}).text if rc_soup.find('span', {'property': 'bookEdition'}) else \"\"\n",
    "            # print(repr(edition))\n",
    "            # else:\n",
    "                # edition = \"\"\n",
    "            author = rc_soup.find('span', {'property': 'author'}).text\n",
    "            # print(repr(author))\n",
    "            contributors = [i.text for i in rc_soup.find_all('span', {'property': 'contributor'})] if rc_soup.find('span', {'property': 'contributor'}) else []\n",
    "            # print(repr(contributors))\n",
    "            series = rc_soup.find('span', {'class': 'series'}).a.text if rc_soup.find('span', {'class': 'series'}) else \"\"\n",
    "            # print(repr(series))\n",
    "            publisher = rc_soup.find('span', {'class': 'publisher_name'}).text[:-2]\n",
    "            # print(repr(publisher))\n",
    "            pub_date = rc_soup.find('span', {'class': 'publisher_date'}).text\n",
    "            # print(repr(pub_date))\n",
    "            pub_place = rc_soup.find('span', {'class': 'publisher_place'}).text[:-2]\n",
    "            # print(repr(pub_place))\n",
    "            desc = rc_soup.find('span', {'property': 'description'}).text\n",
    "            # print(repr(desc))\n",
    "            sub = rc_soup.find('span', {'class': 'subjects'}).ul.text.strip().split('\\n') if rc_soup.find('span', {'class': 'subjects'}) else []\n",
    "            # print(repr(sub))\n",
    "            ddc = rc_soup.find('span', {'class': 'ddc'}).ul.text\n",
    "            # print(repr(ddc))\n",
    "            summary = rc_soup.find('span', {'class': 'summary'}).text[9:] if rc_soup.find('span', {'class': 'summary'}) else \"\"\n",
    "            # print(repr(summary))\n",
    "            \n",
    "            book = {\n",
    "                'Acc. No.': acc_no,\n",
    "                'Acc. Date': acc_date,\n",
    "                'ISBN': isbn,\n",
    "                'Title': title,\n",
    "                'Edition': edition,\n",
    "                'Author': author,\n",
    "                'Contributor(s)': contributors,\n",
    "                'Series': series,\n",
    "                'Publisher': publisher, \n",
    "                'Publication Date': pub_date, \n",
    "                'Publisher Location': pub_place, \n",
    "                'Description': desc, \n",
    "                'Subjects': sub, \n",
    "                'DDC': ddc, \n",
    "                'Summary': summary\n",
    "            }\n",
    "            cleaned_data_table = pd.concat([cleaned_data_table, pd.DataFrame([book])], ignore_index=True)\n",
    "            \n",
    "            print(isbn, 'added')\n",
    "            print(f\"{'-'*30}\")\n",
    "\n",
    "        if not_Found:\n",
    "            with open('notFound.txt', 'a') as nf:\n",
    "                for n in not_Found:\n",
    "                    nf.write(f'{n}\\n')\n",
    "        old_df = pd.read_excel('./CleanedData.xlsx')\n",
    "        pd.concat([old_df, cleaned_data_table], ignore_index=True).to_excel('./CleanedData.xlsx', index=False)\n",
    "    except:\n",
    "        raise LookupError(f\"Failed for {isbn} and i={i}\")\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
